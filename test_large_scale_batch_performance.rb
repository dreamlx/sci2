#!/usr/bin/env ruby
# å¤§è§„æ¨¡æ‰¹é‡å¯¼å…¥æ€§èƒ½å¯¹æ¯”æµ‹è¯•

require_relative 'config/environment'

def generate_large_test_csv(size)
  header = "æŠ¥é”€å•å•å·,å•æ®åç§°,æŠ¥é”€å•ç”³è¯·äºº,æŠ¥é”€å•ç”³è¯·äººå·¥å·,ç”³è¯·äººå…¬å¸,ç”³è¯·äººéƒ¨é—¨,æŠ¥é”€é‡‘é¢ï¼ˆå•æ®å¸ç§ï¼‰,æŠ¥é”€å•çŠ¶æ€\n"
  
  rows = (1..size).map do |i|
    "LARGE_#{i.to_s.rjust(6, '0')},å¤§è§„æ¨¡æµ‹è¯•æŠ¥é”€å•#{i},æµ‹è¯•ç”¨æˆ·#{i % 100},EMP#{(i % 1000).to_s.rjust(4, '0')},æµ‹è¯•å…¬å¸#{i % 10},æµ‹è¯•éƒ¨é—¨#{i % 20},#{rand(1000..10000)},å·²æäº¤"
  end
  
  header + rows.join("\n")
end

def cleanup_large_test_data
  begin
    Reimbursement.where("invoice_number LIKE 'LARGE_%'").delete_all
  rescue => e
    Rails.logger.warn "æ¸…ç†æµ‹è¯•æ•°æ®æ—¶å‡ºç°é”™è¯¯: #{e.message}"
    ActiveRecord::Base.connection.execute("DELETE FROM reimbursements WHERE invoice_number LIKE 'LARGE_%'")
  end
end

puts "ğŸš€ å¤§è§„æ¨¡æ‰¹é‡å¯¼å…¥æ€§èƒ½å¯¹æ¯”æµ‹è¯•"
puts "=" * 60

# åˆ›å»ºæµ‹è¯•ç”¨æˆ·
admin_user = AdminUser.first || AdminUser.create!(
  email: 'test@example.com',
  password: 'password123',
  password_confirmation: 'password123'
)

# æµ‹è¯•ä¸åŒè§„æ¨¡çš„æ•°æ®
test_sizes = [1000, 2000, 5000]

test_sizes.each do |size|
  puts "\nğŸ“Š æµ‹è¯•æ•°æ®è§„æ¨¡: #{size}æ¡è®°å½•"
  puts "=" * 50
  
  # ç”Ÿæˆæµ‹è¯•æ•°æ®
  test_csv_content = generate_large_test_csv(size)
  
  require 'tempfile'
  csv_file = Tempfile.new(['large_test', '.csv'])
  csv_file.write(test_csv_content)
  csv_file.rewind
  
  results = {}
  
  # æµ‹è¯•åŸå§‹å¯¼å…¥æœåŠ¡
  puts "\nğŸ”„ æµ‹è¯•åŸå§‹å¯¼å…¥æœåŠ¡..."
  cleanup_large_test_data
  
  begin
    original_service = ReimbursementImportService.new(csv_file, admin_user)
    start_time = Time.current
    original_result = original_service.import
    original_duration = Time.current - start_time
    
    results[:original] = {
      duration: original_duration.round(3),
      created: original_result[:created],
      updated: original_result[:updated],
      errors: original_result[:errors],
      records_per_second: (size / original_duration).round(2),
      success: original_result[:success]
    }
    
    puts "  âœ… å®Œæˆ"
    puts "  - è€—æ—¶: #{original_duration.round(3)}ç§’"
    puts "  - åˆ›å»º: #{original_result[:created]}æ¡"
    puts "  - é€Ÿåº¦: #{results[:original][:records_per_second]} è®°å½•/ç§’"
    
    # éªŒè¯æ•°æ®
    actual_count = Reimbursement.where("invoice_number LIKE 'LARGE_%'").count
    puts "  - å®é™…å¯¼å…¥: #{actual_count}æ¡"
    
  rescue => e
    puts "  âŒ å¤±è´¥: #{e.message}"
    results[:original] = { error: e.message }
  end
  
  csv_file.rewind
  
  # æµ‹è¯•ç®€åŒ–ç‰ˆæ‰¹é‡å¯¼å…¥æœåŠ¡
  puts "\nâš¡ æµ‹è¯•ç®€åŒ–ç‰ˆæ‰¹é‡å¯¼å…¥æœåŠ¡..."
  cleanup_large_test_data
  
  begin
    batch_service = SimpleBatchReimbursementImportService.new(csv_file, admin_user)
    start_time = Time.current
    batch_result = batch_service.import
    batch_duration = Time.current - start_time
    
    results[:batch] = {
      duration: batch_duration.round(3),
      created: batch_result[:created],
      updated: batch_result[:updated],
      errors: batch_result[:errors],
      records_per_second: (size / batch_duration).round(2),
      success: batch_result[:success]
    }
    
    puts "  âœ… å®Œæˆ"
    puts "  - è€—æ—¶: #{batch_duration.round(3)}ç§’"
    puts "  - åˆ›å»º: #{batch_result[:created]}æ¡"
    puts "  - é€Ÿåº¦: #{results[:batch][:records_per_second]} è®°å½•/ç§’"
    
    # éªŒè¯æ•°æ®
    actual_count = Reimbursement.where("invoice_number LIKE 'LARGE_%'").count
    puts "  - å®é™…å¯¼å…¥: #{actual_count}æ¡"
    
  rescue => e
    puts "  âŒ å¤±è´¥: #{e.message}"
    puts "  é”™è¯¯è¯¦æƒ…: #{e.backtrace.first(3)}"
    results[:batch] = { error: e.message }
  end
  
  # æ€§èƒ½å¯¹æ¯”åˆ†æ
  if results[:original][:duration] && results[:batch][:duration]
    puts "\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”åˆ†æ (#{size}æ¡è®°å½•)"
    puts "-" * 40
    
    original_time = results[:original][:duration]
    batch_time = results[:batch][:duration]
    
    time_improvement = ((original_time - batch_time) / original_time * 100).round(2)
    speed_improvement = (results[:batch][:records_per_second] / results[:original][:records_per_second]).round(2)
    
    puts "åŸå§‹æœåŠ¡:     #{original_time}ç§’ (#{results[:original][:records_per_second]} è®°å½•/ç§’)"
    puts "æ‰¹é‡æœåŠ¡:     #{batch_time}ç§’ (#{results[:batch][:records_per_second]} è®°å½•/ç§’)"
    puts "æ—¶é—´æ”¹å–„:     #{time_improvement > 0 ? '+' : ''}#{time_improvement}%"
    puts "é€Ÿåº¦æå‡:     #{speed_improvement}å€"
    
    if speed_improvement > 10
      puts "ğŸ‰ æ˜¾è‘—æ€§èƒ½æå‡!"
    elsif speed_improvement > 3
      puts "âœ… è‰¯å¥½æ€§èƒ½æå‡"
    elsif speed_improvement > 1
      puts "â¡ï¸  è½»å¾®æ€§èƒ½æå‡"
    else
      puts "âš ï¸  æ€§èƒ½æœªæå‡"
    end
    
    # é¢„æµ‹å¤§è§„æ¨¡æ•°æ®å¤„ç†æ—¶é—´
    puts "\nğŸ”® å¤§è§„æ¨¡æ•°æ®å¤„ç†æ—¶é—´é¢„æµ‹:"
    [10000, 20000, 50000].each do |scale|
      original_predicted = (scale / results[:original][:records_per_second]).round(1)
      batch_predicted = (scale / results[:batch][:records_per_second]).round(1)
      puts "  #{scale}æ¡è®°å½•: åŸå§‹#{original_predicted}ç§’ â†’ æ‰¹é‡#{batch_predicted}ç§’"
    end
  end
  
  # æ¸…ç†æµ‹è¯•æ•°æ®
  cleanup_large_test_data
  csv_file.close
  csv_file.unlink
  
  puts "\n" + "=" * 50
end

puts "\nğŸ‰ å¤§è§„æ¨¡æ‰¹é‡å¯¼å…¥æ€§èƒ½æµ‹è¯•å®Œæˆ!"